from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestRegressor
from scipy.sparse import hstack, vstack
from sklearn.metrics import recall_score, f1_score, precision_score
from datetime import datetime
from sklearn.utils import shuffle
from tqdm import tqdm
import numpy as np
import pandas as pd

from utils import one_hot_encode_batch, plot_confusion, load_dataset, save_encoded_data, load_encoded_data

def train_random_forest(X_train, y_train, n_estimators = None, min_samples_split=2, max_depth = None, min_samples_leaf=1):
    # Following the seed tradition here?? lol https://www.reddit.com/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/
    # When n jobs is -1, utilizes all cores to train ASAP
    random_forest_model = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)
    random_forest_model.fit(X_train, y_train)
    return random_forest_model


def compute_top1_f1_score(model, seq1_encoded, seq2_encoded, merged_df, val_idx):
    y_true = []
    y_pred = []

    for i in tqdm(val_idx):
        # Get the seq1 encoding for the current validation index only
        seq1 = seq1_encoded[i] 
        seq_2s_to_score_with_seq_1 = []
        true_labels = []

        scores_against_seq1 = []
        # Pair seq1 with all other seq2, where the true match has label 1 and is otherwise 0
        for j in val_idx:
            seq2 = seq2_encoded[j]
            
            label = 1 if i == j else 0 
            true_labels.append(label)

            # Concatenate seq1 and seq2 as in training phase
            pair_input = hstack([seq1, seq2])
            seq_2s_to_score_with_seq_1.append(pair_input)
        
        input_batch = vstack(seq_2s_to_score_with_seq_1)
        scores_against_seq1 = model.predict(input_batch)
        # Find top-1 prediction (index with the highest output value)
        top1_idx = np.argmax(scores_against_seq1)
        predicted_label = 1 if true_labels[top1_idx] == 1 else 0

        # Append true label (always 1, because seq1 has exactly one match)
        y_true.append(1)
        # Predicted label is either 1, if the true match was the top match, and 0 otherwise, meaning it failed to produce the correct top
        y_pred.append(predicted_label)

    # Compute precision, recall, and F1 score based on the true vs predicted labels
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    print(f"Top-1 Precision: {precision:.4f}")
    print(f"Top-1 Recall: {recall:.4f}")
    print(f"Top-1 F1 Score: {f1:.4f}")
    plot_confusion(y_pred, y_true )
    return {"precision": precision, "recall": recall, "f1": f1}


def main():
    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")
    print("LOADING BACARCH DATASET, ADDING NEGATIVE SAMPLES, AND SHUFFLING....")
    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")    
    raw_dataframe = load_dataset('BacArch')
    raw_dataframe["pair_id"] = range(len(raw_dataframe))
    raw_dataframe["source"] = "original"

    merged_df = raw_dataframe.sample(frac=1, random_state=42)

    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")
    print("PADDING AND ENCODING SEQ 1 and SEQ 2 COLS....")
    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")    
    encoded_filename = 'encoded_sequences.pkl'
    loaded_encodings = load_encoded_data(encoded_filename)
    if loaded_encodings is None:
        seq1_df = merged_df[['Seq1']].copy()
        seq1_df.columns = ['MatchedSeqs']
        seq2_df = merged_df[['Seq2']].copy()
        seq2_df.columns = ['MatchedSeqs']

        seq1_encoded = one_hot_encode_batch(seq1_df, 1000)
        seq2_encoded = one_hot_encode_batch(seq2_df, 1000)

        save_encoded_data(seq1_encoded, seq2_encoded, encoded_filename)
    else:
        seq1_encoded, seq2_encoded = loaded_encodings

    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")
    print("CONCATENATING COLS FOR INPUTS....")
    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")   
    X = hstack([seq1_encoded, seq2_encoded]) 
    y = np.array(merged_df["Label"])

    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")
    print("TRAINING AND EVALUATING RANDOM FOREST WITH K-FOLD CROSS-VALIDATION....")
    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")    
    k_folds = 5
    fold_metrics = []

    k_fold = StratifiedKFold(n_splits = k_folds, shuffle=True, random_state=42)

    for fold, (train_idx, val_idx) in enumerate(k_fold.split(X, y)):
        print(f"\nTraining fold {fold+1}/{k_folds}...")

        # Assign training and validation sets
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # print(train_idx)
        # print(val_idx)

        flipped_pos_samples = []
        for i in train_idx:
            seq1 = seq1_encoded[i]
            seq2 = seq2_encoded[i]
            flipped_pos_samples.append(hstack([seq2, seq1]))

        # Create negative samples for the train set by pairing each Seq1 with all other Seq2
        neg_samples = []
        for i in train_idx:
            seq1 = seq1_encoded[i]
            for j in train_idx:
                # except itself
                if i != j:
                    seq2 = seq2_encoded[j]
                    # We know these are not similar as there is only 1 true match in the dataset
                    neg_samples.append(hstack([seq1, seq2]))

        X_neg = vstack(neg_samples)
        y_neg = np.zeros(X_neg.shape[0])
        # X_neg, y_neg = shuffle(X_neg, y_neg, random_state=42)
        # X_neg = X_neg[:250]
        # y_neg = y_neg[:250]

        X_pos_flipped = vstack(flipped_pos_samples)
        y_pos_flipped = np.ones(X_pos_flipped.shape[0])

        repeat_factor = 3
        X_pos_repeated = vstack([X_train[y_train == 1]] * repeat_factor)
        y_pos_repeated = np.ones(X_pos_repeated.shape[0])

        X_train = vstack([X_train, X_neg, X_pos_flipped, X_pos_repeated])
        y_train = np.concatenate([y_train, y_neg, y_pos_flipped, y_pos_repeated])

        X_train, y_train = shuffle(X_train, y_train, random_state=42)

        # PASS YOUR HYPERPARAMS HERE
        random_forest_model = train_random_forest(X_train, y_train, n_estimators=50, max_depth=15, min_samples_split=10)

        metrics = compute_top1_f1_score(random_forest_model, seq1_encoded, seq2_encoded, merged_df, val_idx)
        fold_metrics.append(metrics)
        

    # After cross-validation, calculate average metrics across all folds
    avg_precision = np.mean([metrics['precision'] for metrics in fold_metrics])
    avg_recall = np.mean([metrics['recall'] for metrics in fold_metrics])
    avg_f1 = np.mean([metrics['f1'] for metrics in fold_metrics])

    print(f"\nAverage Metrics across {k_folds} folds:")
    print(f"Precision: {avg_precision:.4f}")
    print(f"Recall: {avg_recall:.4f}")
    print(f"F1: {avg_f1:.4f}")

    metrics_df = pd.DataFrame(fold_metrics)
    date = datetime.now()

    metrics_df.to_csv(f'rf_fold_metrics_{date}.csv', index=False)

if __name__ == "__main__":
    main()